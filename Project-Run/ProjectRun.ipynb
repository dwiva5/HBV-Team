{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Run Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run\n",
    "from neuralhydrology.nh_run_scheduler import schedule_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model\n",
    "\n",
    "1. Base Model = LSTM without dropout rate\n",
    "2. MCD Model = LSTM with Regression head, Monte Carlo Dropout, and dropout rate\n",
    "3. UMAL Model = LSTM with UMAL head and dropout rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    start_run(config_file=Path(\"base_model_cudalstm.yml\"))\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    start_run(config_file=Path(\"base_model_cudalstm.yml\"), gpu=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    start_run(config_file=Path(\"mcd_model_cudalstm.yml\"))\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    start_run(config_file=Path(\"mcd_model_cudalstm.yml\"), gpu=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default we assume that you have at least one CUDA-capable NVIDIA GPU\n",
    "if torch.cuda.is_available():\n",
    "    start_run(config_file=Path(\"umal_model_cudalstm.yml\"))\n",
    "\n",
    "# fall back to CPU-only mode\n",
    "else:\n",
    "    start_run(config_file=Path(\"umal_model_cudalstm.yml\"), gpu=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate run on test set\n",
    "The run directory that needs to be specified for evaluation is printed in the output log above. Since the folder name is created dynamically (including the date and time of the start of the run) you will need to change the `run_dir` argument according to your local directory name. By default, it will use the same device as during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = Path(\"runs/test_run_1601_104731\")\n",
    "eval_run(run_dir=run_dir, period=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and inspect model predictions\n",
    "Next, we load the results file and compare the model predictions with observations. The results file is always a pickled dictionary with one key per basin (even for a single basin). The next-lower dictionary level is the temporal resolution of the predictions. In this case, we trained a model only on daily data ('1D'). Within the temporal resolution, the next-lower dictionary level are `xr`(an xarray Dataset that contains observations and predictions), as well as one key for each metric that was specified in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(run_dir / \"test\" / \"model_epoch050\" / \"test_results.p\", \"rb\") as fp:\n",
    "    results = pickle.load(fp)\n",
    "    \n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data variables in the xarray Dataset are named according to the name of the target variables, with suffix `_obs` for the observations and suffix `_sim` for the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['10258000']['1D']['xr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model predictions vs. the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract observations and simulations\n",
    "qobs = results['10258000']['1D']['xr']['QObs(mm/d)_obs']\n",
    "qsim = results['10258000']['1D']['xr']['QObs(mm/d)_sim']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.plot(qobs['date'], qobs)\n",
    "#ax.plot(qsim['date'], qsim)\n",
    "ax.set_ylabel(\"Discharge (mm/d)\")\n",
    "ax.set_title(f\"Test period - NSE {results['10258000']['1D']['NSE']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.evaluation.plots import percentile_plot, regression_plot, uncertainty_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qobstest = qobs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract observations and simulations\n",
    "qobs = results['10258000']['1D']['xr']['QObs(mm/d)_obs']\n",
    "qsim = results['10258000']['1D']['xr']['QObs(mm/d)_sim']\n",
    "\n",
    "# Plot observations\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "ax.plot(qobs['date'], qobs, label='Observations')\n",
    "\n",
    "# Plot all simulation samples\n",
    "for i in range(qsim.shape[2]):\n",
    "    ax.plot(qsim['date'], qsim.isel(samples=i), color='orange', alpha=0.2, label='_nolegend_')  # Plot each sample with low alpha for transparency\n",
    "\n",
    "ax.set_ylabel(\"Discharge (mm/d)\")\n",
    "ax.set_title(f\"Test period - NSE {results['10258000']['1D']['NSE']:.3f}\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_plot(qobstest, qsim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to compute all metrics that are implemented in the NeuralHydrology package. You will find additional hydrological signatures implemented in `neuralhydrology.evaluation.signatures`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = metrics.calculate_all_metrics(qobs.isel(time_step=-1), qsim.isel(time_step=-1))\n",
    "for key, val in values.items():\n",
    "    print(f\"{key}: {val:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
