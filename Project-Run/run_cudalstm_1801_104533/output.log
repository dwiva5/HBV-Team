2024-01-18 10:45:33,622: Logging to /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_104533/output.log initialized.
2024-01-18 10:45:33,623: ### Folder structure created at /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_104533
2024-01-18 10:45:33,624: ### Run configurations for run_cudalstm
2024-01-18 10:45:33,625: experiment_name: run_cudalstm
2024-01-18 10:45:33,626: train_basin_file: basin_huc_17.txt
2024-01-18 10:45:33,627: validation_basin_file: basin_huc_17.txt
2024-01-18 10:45:33,628: test_basin_file: basin_huc_17.txt
2024-01-18 10:45:33,629: train_start_date: 1999-10-01 00:00:00
2024-01-18 10:45:33,630: train_end_date: 2008-09-30 00:00:00
2024-01-18 10:45:33,631: validation_start_date: 1980-10-01 00:00:00
2024-01-18 10:45:33,631: validation_end_date: 1989-09-30 00:00:00
2024-01-18 10:45:33,632: test_start_date: 1989-10-01 00:00:00
2024-01-18 10:45:33,633: test_end_date: 1999-09-30 00:00:00
2024-01-18 10:45:33,637: device: cuda:0
2024-01-18 10:45:33,638: validate_every: 3
2024-01-18 10:45:33,639: validate_n_random_basins: 91
2024-01-18 10:45:33,640: metrics: ['NSE']
2024-01-18 10:45:33,641: model: cudalstm
2024-01-18 10:45:33,641: head: regression
2024-01-18 10:45:33,642: output_activation: linear
2024-01-18 10:45:33,643: hidden_size: 20
2024-01-18 10:45:33,644: initial_forget_bias: 3
2024-01-18 10:45:33,645: mc_dropout: True
2024-01-18 10:45:33,646: n_samples: 20
2024-01-18 10:45:33,647: negative_sample_handling: clip
2024-01-18 10:45:33,648: output_dropout: 0.4
2024-01-18 10:45:33,649: optimizer: Adam
2024-01-18 10:45:33,649: loss: MSE
2024-01-18 10:45:33,651: learning_rate: {0: 0.01, 30: 0.005, 40: 0.001}
2024-01-18 10:45:33,651: batch_size: 256
2024-01-18 10:45:33,652: epochs: 50
2024-01-18 10:45:33,653: clip_gradient_norm: 1
2024-01-18 10:45:33,654: predict_last_n: 1
2024-01-18 10:45:33,655: seq_length: 365
2024-01-18 10:45:33,655: num_workers: 8
2024-01-18 10:45:33,656: log_interval: 5
2024-01-18 10:45:33,658: log_tensorboard: True
2024-01-18 10:45:33,659: log_n_figures: 1
2024-01-18 10:45:33,659: save_weights_every: 1
2024-01-18 10:45:33,660: dataset: camels_us
2024-01-18 10:45:33,661: data_dir: ../data/CAMELS_US
2024-01-18 10:45:33,662: forcings: ['maurer', 'daymet', 'nldas']
2024-01-18 10:45:33,663: dynamic_inputs: ['PRCP(mm/day)_nldas', 'PRCP(mm/day)_maurer', 'prcp(mm/day)_daymet', 'srad(W/m2)_daymet', 'tmax(C)_daymet', 'tmin(C)_daymet', 'vp(Pa)_daymet']
2024-01-18 10:45:33,664: target_variables: ['QObs(mm/d)']
2024-01-18 10:45:33,664: clip_targets_to_zero: ['QObs(mm/d)']
2024-01-18 10:45:33,666: number_of_basins: 91
2024-01-18 10:45:33,667: run_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_104533
2024-01-18 10:45:33,667: train_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_104533/train_data
2024-01-18 10:45:33,668: img_log_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_104533/img_log
2024-01-18 10:45:33,692: ### Device cuda:0 will be used for training
2024-01-18 10:45:33,693: Loading basin data into xarray data set.
2024-01-18 10:45:49,560: Create lookup table and convert to pytorch tensor
2024-01-18 10:46:34,321: Epoch 1 average loss: avg_loss: 0.16092, avg_total_loss: 0.16092
2024-01-18 10:47:07,217: Epoch 2 average loss: avg_loss: 0.13384, avg_total_loss: 0.13384
2024-01-18 10:47:40,244: Epoch 3 average loss: avg_loss: 0.12911, avg_total_loss: 0.12911
2024-01-18 10:49:45,927: Epoch 3 average validation loss: 0.11931 -- Median validation metrics: avg_loss: 0.11931, NSE: 0.67091
2024-01-18 10:50:18,904: Epoch 4 average loss: avg_loss: 0.12207, avg_total_loss: 0.12207
2024-01-18 10:50:51,008: Epoch 5 average loss: avg_loss: 0.11874, avg_total_loss: 0.11874
2024-01-18 10:51:24,165: Epoch 6 average loss: avg_loss: 0.11931, avg_total_loss: 0.11931
2024-01-18 10:53:10,618: Epoch 6 average validation loss: 0.11501 -- Median validation metrics: avg_loss: 0.11501, NSE: 0.70041
2024-01-18 10:53:43,044: Epoch 7 average loss: avg_loss: 0.11681, avg_total_loss: 0.11681
2024-01-18 10:54:16,007: Epoch 8 average loss: avg_loss: 0.11425, avg_total_loss: 0.11425
2024-01-18 10:54:48,415: Epoch 9 average loss: avg_loss: 0.11539, avg_total_loss: 0.11539
2024-01-18 10:56:36,332: Epoch 9 average validation loss: 0.10883 -- Median validation metrics: avg_loss: 0.10883, NSE: 0.72631
2024-01-18 10:57:09,536: Epoch 10 average loss: avg_loss: 0.11356, avg_total_loss: 0.11356
2024-01-18 10:57:42,836: Epoch 11 average loss: avg_loss: 0.11669, avg_total_loss: 0.11669
2024-01-18 10:58:16,053: Epoch 12 average loss: avg_loss: 0.11371, avg_total_loss: 0.11371
2024-01-18 11:00:03,930: Epoch 12 average validation loss: 0.13737 -- Median validation metrics: avg_loss: 0.13737, NSE: 0.60985
2024-01-18 11:00:37,011: Epoch 13 average loss: avg_loss: 0.11300, avg_total_loss: 0.11300
2024-01-18 11:01:10,256: Epoch 14 average loss: avg_loss: 0.11476, avg_total_loss: 0.11476
2024-01-18 11:01:43,334: Epoch 15 average loss: avg_loss: 0.11356, avg_total_loss: 0.11356
2024-01-18 11:03:30,840: Epoch 15 average validation loss: 0.14199 -- Median validation metrics: avg_loss: 0.14199, NSE: 0.60083
2024-01-18 11:04:04,310: Epoch 16 average loss: avg_loss: 0.11173, avg_total_loss: 0.11173
2024-01-18 11:04:38,027: Epoch 17 average loss: avg_loss: 0.11135, avg_total_loss: 0.11135
2024-01-18 11:05:11,346: Epoch 18 average loss: avg_loss: 0.11229, avg_total_loss: 0.11229
2024-01-18 11:06:59,136: Epoch 18 average validation loss: 0.13237 -- Median validation metrics: avg_loss: 0.13237, NSE: 0.63610
2024-01-18 11:07:31,532: Epoch 19 average loss: avg_loss: 0.11022, avg_total_loss: 0.11022
2024-01-18 11:08:04,645: Epoch 20 average loss: avg_loss: 0.10467, avg_total_loss: 0.10467
2024-01-18 11:08:37,641: Epoch 21 average loss: avg_loss: 0.10455, avg_total_loss: 0.10455
2024-01-18 11:10:25,630: Epoch 21 average validation loss: 0.13826 -- Median validation metrics: avg_loss: 0.13826, NSE: 0.60972
2024-01-18 11:10:58,721: Epoch 22 average loss: avg_loss: 0.11310, avg_total_loss: 0.11310
2024-01-18 11:11:31,747: Epoch 23 average loss: avg_loss: 0.10715, avg_total_loss: 0.10715
2024-01-18 11:12:04,849: Epoch 24 average loss: avg_loss: 0.10641, avg_total_loss: 0.10641
2024-01-18 11:13:53,374: Epoch 24 average validation loss: 0.13181 -- Median validation metrics: avg_loss: 0.13181, NSE: 0.65078
2024-01-18 11:14:26,443: Epoch 25 average loss: avg_loss: 0.10666, avg_total_loss: 0.10666
2024-01-18 11:14:59,507: Epoch 26 average loss: avg_loss: 0.10391, avg_total_loss: 0.10391
2024-01-18 11:15:32,614: Epoch 27 average loss: avg_loss: 0.10725, avg_total_loss: 0.10725
2024-01-18 11:17:20,647: Epoch 27 average validation loss: 0.11554 -- Median validation metrics: avg_loss: 0.11554, NSE: 0.67375
2024-01-18 11:17:53,742: Epoch 28 average loss: avg_loss: 0.10924, avg_total_loss: 0.10924
2024-01-18 11:18:26,636: Epoch 29 average loss: avg_loss: 0.10472, avg_total_loss: 0.10472
2024-01-18 11:18:26,644: Setting learning rate to 0.005
2024-01-18 11:18:59,748: Epoch 30 average loss: avg_loss: 0.09464, avg_total_loss: 0.09464
2024-01-18 11:20:48,127: Epoch 30 average validation loss: 0.12309 -- Median validation metrics: avg_loss: 0.12309, NSE: 0.65786
2024-01-18 11:21:21,238: Epoch 31 average loss: avg_loss: 0.09851, avg_total_loss: 0.09851
2024-01-18 11:21:54,346: Epoch 32 average loss: avg_loss: 0.09312, avg_total_loss: 0.09312
2024-01-18 11:22:27,416: Epoch 33 average loss: avg_loss: 0.09277, avg_total_loss: 0.09277
2024-01-18 11:24:14,508: Epoch 33 average validation loss: 0.12968 -- Median validation metrics: avg_loss: 0.12968, NSE: 0.64077
2024-01-18 11:24:47,518: Epoch 34 average loss: avg_loss: 0.09456, avg_total_loss: 0.09456
2024-01-18 11:25:20,539: Epoch 35 average loss: avg_loss: 0.09366, avg_total_loss: 0.09366
2024-01-18 11:25:53,956: Epoch 36 average loss: avg_loss: 0.09537, avg_total_loss: 0.09537
2024-01-18 11:27:42,202: Epoch 36 average validation loss: 0.14860 -- Median validation metrics: avg_loss: 0.14860, NSE: 0.59994
2024-01-18 11:28:15,139: Epoch 37 average loss: avg_loss: 0.09210, avg_total_loss: 0.09210
2024-01-18 11:28:48,345: Epoch 38 average loss: avg_loss: 0.09330, avg_total_loss: 0.09330
2024-01-18 11:29:21,520: Epoch 39 average loss: avg_loss: 0.09231, avg_total_loss: 0.09231
2024-01-18 11:31:09,535: Epoch 39 average validation loss: 0.15487 -- Median validation metrics: avg_loss: 0.15487, NSE: 0.53494
2024-01-18 11:31:09,537: Setting learning rate to 0.001
2024-01-18 11:31:42,644: Epoch 40 average loss: avg_loss: 0.08856, avg_total_loss: 0.08856
2024-01-18 11:32:15,620: Epoch 41 average loss: avg_loss: 0.08544, avg_total_loss: 0.08544
2024-01-18 11:32:48,619: Epoch 42 average loss: avg_loss: 0.08613, avg_total_loss: 0.08613
2024-01-18 11:34:36,521: Epoch 42 average validation loss: 0.13248 -- Median validation metrics: avg_loss: 0.13248, NSE: 0.64916
2024-01-18 11:35:11,320: Epoch 43 average loss: avg_loss: 0.08299, avg_total_loss: 0.08299
2024-01-18 11:35:45,541: Epoch 44 average loss: avg_loss: 0.08328, avg_total_loss: 0.08328
2024-01-18 11:36:20,446: Epoch 45 average loss: avg_loss: 0.08588, avg_total_loss: 0.08588
2024-01-18 11:38:08,816: Epoch 45 average validation loss: 0.12705 -- Median validation metrics: avg_loss: 0.12705, NSE: 0.67428
2024-01-18 11:38:40,621: Epoch 46 average loss: avg_loss: 0.08417, avg_total_loss: 0.08417
2024-01-18 11:39:13,922: Epoch 47 average loss: avg_loss: 0.08223, avg_total_loss: 0.08223
2024-01-18 11:39:46,915: Epoch 48 average loss: avg_loss: 0.08313, avg_total_loss: 0.08313
2024-01-18 11:41:34,461: Epoch 48 average validation loss: 0.13353 -- Median validation metrics: avg_loss: 0.13353, NSE: 0.64243
2024-01-18 11:42:06,849: Epoch 49 average loss: avg_loss: 0.08178, avg_total_loss: 0.08178
2024-01-18 11:42:39,749: Epoch 50 average loss: avg_loss: 0.08116, avg_total_loss: 0.08116
2024-01-18 11:43:33,464: Using the model weights from runs/run_cudalstm_1801_104533/model_epoch050.pt
2024-01-18 11:45:36,422: Stored metrics at runs/run_cudalstm_1801_104533/test/model_epoch050/test_metrics.csv
2024-01-18 11:45:36,485: Stored results at runs/run_cudalstm_1801_104533/test/model_epoch050/test_results.p
2024-01-18 13:00:28,673: Logging to /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_130028/output.log initialized.
2024-01-18 13:00:28,674: ### Folder structure created at /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_130028
2024-01-18 13:00:28,676: ### Run configurations for run_cudalstm
2024-01-18 13:00:28,677: experiment_name: run_cudalstm
2024-01-18 13:00:28,678: train_basin_file: basin_huc_17.txt
2024-01-18 13:00:28,679: validation_basin_file: basin_huc_17.txt
2024-01-18 13:00:28,680: test_basin_file: basin_huc_17.txt
2024-01-18 13:00:28,682: train_start_date: 1999-10-01 00:00:00
2024-01-18 13:00:28,683: train_end_date: 2008-09-30 00:00:00
2024-01-18 13:00:28,684: validation_start_date: 1980-10-01 00:00:00
2024-01-18 13:00:28,685: validation_end_date: 1989-09-30 00:00:00
2024-01-18 13:00:28,686: test_start_date: 1989-10-01 00:00:00
2024-01-18 13:00:28,688: test_end_date: 1999-09-30 00:00:00
2024-01-18 13:00:28,691: device: cuda:0
2024-01-18 13:00:28,692: validate_every: 3
2024-01-18 13:00:28,693: validate_n_random_basins: 91
2024-01-18 13:00:28,694: metrics: ['NSE']
2024-01-18 13:00:28,695: model: cudalstm
2024-01-18 13:00:28,696: head: regression
2024-01-18 13:00:28,697: output_activation: linear
2024-01-18 13:00:28,698: hidden_size: 20
2024-01-18 13:00:28,699: initial_forget_bias: 3
2024-01-18 13:00:28,700: mc_dropout: True
2024-01-18 13:00:28,701: n_samples: 20
2024-01-18 13:00:28,702: negative_sample_handling: clip
2024-01-18 13:00:28,703: output_dropout: 0.4
2024-01-18 13:00:28,704: optimizer: Adam
2024-01-18 13:00:28,705: loss: MSE
2024-01-18 13:00:28,706: learning_rate: {0: 0.01, 30: 0.005, 40: 0.001}
2024-01-18 13:00:28,707: batch_size: 256
2024-01-18 13:00:28,708: epochs: 50
2024-01-18 13:00:28,709: clip_gradient_norm: 1
2024-01-18 13:00:28,710: predict_last_n: 1
2024-01-18 13:00:28,711: seq_length: 365
2024-01-18 13:00:28,712: num_workers: 8
2024-01-18 13:00:28,713: log_interval: 5
2024-01-18 13:00:28,714: log_tensorboard: True
2024-01-18 13:00:28,715: log_n_figures: 1
2024-01-18 13:00:28,717: save_weights_every: 1
2024-01-18 13:00:28,717: dataset: camels_us
2024-01-18 13:00:28,718: data_dir: ../data/CAMELS_US
2024-01-18 13:00:28,719: forcings: ['maurer', 'daymet', 'nldas']
2024-01-18 13:00:28,720: dynamic_inputs: ['PRCP(mm/day)_nldas', 'PRCP(mm/day)_maurer', 'prcp(mm/day)_daymet', 'srad(W/m2)_daymet', 'tmax(C)_daymet', 'tmin(C)_daymet', 'vp(Pa)_daymet']
2024-01-18 13:00:28,721: target_variables: ['QObs(mm/d)']
2024-01-18 13:00:28,722: clip_targets_to_zero: ['QObs(mm/d)']
2024-01-18 13:00:28,723: number_of_basins: 91
2024-01-18 13:00:28,724: run_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_130028
2024-01-18 13:00:28,725: train_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_130028/train_data
2024-01-18 13:00:28,726: img_log_dir: /workspace/hbv-runoff/Project-Run/runs/run_cudalstm_1801_130028/img_log
2024-01-18 13:00:28,728: ### Device cuda:0 will be used for training
2024-01-18 13:00:28,729: Loading basin data into xarray data set.
2024-01-18 13:00:44,116: Create lookup table and convert to pytorch tensor
2024-01-18 13:01:30,264: Task was destroyed but it is pending!
task: <Task pending name='Task-3' coro=<Kernel.poll_control_queue() running at /usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py:285> wait_for=<Future finished result=<Future at 0x...state=pending>> cb=[_chain_future.<locals>._call_set_state() at /usr/lib/python3.8/asyncio/futures.py:367]>
