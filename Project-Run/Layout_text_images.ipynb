{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb2dd8f-64e4-4119-973a-d872af9f3945",
   "metadata": {},
   "source": [
    "# Uncertainty estimation with deep learning for discharge prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2d48a-ee9f-40d9-b4b4-eca3f771490b",
   "metadata": {},
   "source": [
    "This is a project for the course CEGM2003 Data Science and Artificial Intelligence for Engineers,\n",
    "created by the members of the HBV Group: \n",
    "- Dwiva Anbiya Taruna (5849578)\n",
    "- Konstantina Bourazani (5728347)\n",
    "- Hang Long (5743702)\n",
    "- Thomas Poort (4715500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e610dab8-581c-410a-ae5d-7549bf4fc2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from neuralhydrology.evaluation import metrics\n",
    "from neuralhydrology.nh_run import start_run, eval_run\n",
    "from neuralhydrology.utils.nh_results_ensemble import create_results_ensemble\n",
    "from neuralhydrology.nh_run_scheduler import schedule_runs\n",
    "from neuralhydrology.evaluation.plots import percentile_plot, regression_plot, uncertainty_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73871d18-86b2-44ad-a3f0-90f09814f5dc",
   "metadata": {},
   "source": [
    "## Introduction\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb15905-e54b-4f65-a1a7-8d63f51f0a7b",
   "metadata": {},
   "source": [
    "Rainfall runoff modeling is extremely important for hydrological science as it plays an huge role in understanding and managing water resources. The water cycle, containing factors such as precipitation and evaporation, contains many interactions between the atmosphere, the land surface and the river system. Understanding each of these factors and how they impact the river systems is extremely important. Especially in current times of climate change and urbanization that continues to reshape landscapes, there is a need for accurate and reliable rainfall runoff models. In the past years it has become increasingly apparent that the climate has been changing and that river systems have been impacted greatly in the forms of droughts or floods.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5e890-e262-4b00-b63a-6c76b78bf287",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "  <img src=\"Images/droughts_river_france.jpg\" width=400/>\n",
    "  <img src=\"Images/floods_river_germany.jpg\" width=400/>\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d15af9-0083-4db2-8673-3c4ca523feda",
   "metadata": {},
   "source": [
    "Therefore, predicting the runoff in river systems is crucial for a multitude of applications, such as water resource management, flood risk assessment, urban planning or early warning systems. Hydrological prediction is important in effective water resource management, playing a pivotal role in addressing the challenges posed by climate variability and change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ac817-8128-4d96-9d5b-8c19c4117eb4",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "  <img src=\"Images/rainfall_runoff.jpg\" width=600/>\n",
    "<figcaption>Rainfall-Runoff\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d161174-d105-4603-9e7f-e01efdb7bb61",
   "metadata": {},
   "source": [
    "However, until now rainfall predictions have been computed deterministically without providing any information about the uncertainty that plays a significant role in these predictions. It is crucial to quantify uncertainties in rainfall-runoff predictions for multiple reasons, as it provides stakeholders a better understanding of the the possible outcoems that could occur. Therefore it is crucial for decision-making in many sectors, for example water resource management, agriculture and disaster risk reduction. \n",
    "\n",
    "\n",
    "For that reason there is a need to estimate the uncertainty by using probabilistic predictions instead of deterministic ones. The main goal of this project is to investigate different methods for uncertainty estimation in discharge prediction using probabilistic predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c29ea6-366b-4728-866e-4327ca45760f",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d0426-1988-4c37-a89f-275040c8f9b1",
   "metadata": {},
   "source": [
    "The project has four objectives:\n",
    "\n",
    "•\t**Hands-on Discharge prediction:** \n",
    "    \n",
    "    - Gain practical experience in discharge prediction using machine learning techniques.\n",
    "\n",
    "•\t**Uncertainty Estimation for Discharge Prediction:**\n",
    "\n",
    "    - Use a LSTM model combined with Monte Carlo Dropout to make probabilistic predictions.\n",
    "\n",
    "•\t**Evaluation Metrics Exploration:** \n",
    "\n",
    "    - Probabilistic: Explore suitable metrics (PICP, PINAW) for evaluating the performance of various uncertainty estimation methods.\n",
    "    - Deterministic: Using the ensemble of the MCD output, compare to the LSTM predictions.\n",
    "\n",
    "•\t**Transfer Learning:** \n",
    "\n",
    "    - Assess whether the obtained model can be used for Transfer Learning for different basins.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc1073-9b1d-4c71-9a7d-e4c3fd4b299c",
   "metadata": {},
   "source": [
    "For that purpose the following workplan/flowchart was created:\n",
    "\n",
    "<center><figure>\n",
    "  <img src=\"Images/CEGM2003_new.png\" width=600/>\n",
    "<figcaption>Workplan\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fad800-cc17-45b2-8501-1015500d6785",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73717ef6-1ae8-45f0-99f4-ceff7e150bac",
   "metadata": {},
   "source": [
    "For this project data was used from the CAMELS US dataset (Catchment Attributes and Meteorology for Large-sample Studies). This dataset contains of two main aspects; the hydrometeorological time series of each basin and the catchment attributes. \n",
    "\n",
    "\r\n",
    "The hydrometeorological time series contains all the meteorological data that is used as input as well as time series of streamflow observations for each basin. The catchment attributes dataset contains information about a wide range of attributes that are able to influence catchment behaviour such as topographic characteristics (slope, elevation), soil characteristics (soil depth, porosity), geological characteristics etc.\n",
    "\n",
    " \r\n",
    "From this dataset that contains in total 671 catchments in the United States, one specific hydrological unit (HUC) was selected to use as input data for our model. The selected region was HUC 17 which is the North-Western area of the United States including for instance the states of Washington and Oregon.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dafc5f-61af-4e9e-969a-edbe3ad899bc",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "  <img src=\"Images/CAMELS_US_HUC.png\" width=600/>\n",
    "<figcaption>CAMELS US Data\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4628805-9498-4347-a386-b00aaf02ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralhydrology.datasetzoo.camelsus import CamelsUS, load_camels_us_attributes, load_camels_us_discharge, load_camels_us_forcings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b30c3f88-30e0-40f2-9f1d-cb30863667d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_mean</th>\n",
       "      <th>pet_mean</th>\n",
       "      <th>p_seasonality</th>\n",
       "      <th>frac_snow</th>\n",
       "      <th>aridity</th>\n",
       "      <th>high_prec_freq</th>\n",
       "      <th>high_prec_dur</th>\n",
       "      <th>high_prec_timing</th>\n",
       "      <th>low_prec_freq</th>\n",
       "      <th>low_prec_dur</th>\n",
       "      <th>...</th>\n",
       "      <th>frac_forest</th>\n",
       "      <th>lai_max</th>\n",
       "      <th>lai_diff</th>\n",
       "      <th>gvf_max</th>\n",
       "      <th>gvf_diff</th>\n",
       "      <th>dom_land_cover_frac</th>\n",
       "      <th>dom_land_cover</th>\n",
       "      <th>root_depth_50</th>\n",
       "      <th>root_depth_99</th>\n",
       "      <th>huc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gauge_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10396000</th>\n",
       "      <td>1.560339</td>\n",
       "      <td>3.394634</td>\n",
       "      <td>-0.575570</td>\n",
       "      <td>0.465490</td>\n",
       "      <td>2.175574</td>\n",
       "      <td>24.00</td>\n",
       "      <td>1.307902</td>\n",
       "      <td>mam</td>\n",
       "      <td>277.90</td>\n",
       "      <td>7.236979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.758705</td>\n",
       "      <td>0.565572</td>\n",
       "      <td>0.331168</td>\n",
       "      <td>0.177819</td>\n",
       "      <td>0.999126</td>\n",
       "      <td>Grasslands</td>\n",
       "      <td>0.120052</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12010000</th>\n",
       "      <td>7.927943</td>\n",
       "      <td>1.967121</td>\n",
       "      <td>-0.761100</td>\n",
       "      <td>0.023636</td>\n",
       "      <td>0.248125</td>\n",
       "      <td>9.35</td>\n",
       "      <td>1.316901</td>\n",
       "      <td>djf</td>\n",
       "      <td>169.90</td>\n",
       "      <td>4.323155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>4.329237</td>\n",
       "      <td>2.369540</td>\n",
       "      <td>0.860577</td>\n",
       "      <td>0.133434</td>\n",
       "      <td>0.607243</td>\n",
       "      <td>Evergreen Needleleaf Forest</td>\n",
       "      <td>0.201421</td>\n",
       "      <td>2.035654</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013500</th>\n",
       "      <td>6.874938</td>\n",
       "      <td>2.116710</td>\n",
       "      <td>-0.799301</td>\n",
       "      <td>0.017416</td>\n",
       "      <td>0.307888</td>\n",
       "      <td>11.35</td>\n",
       "      <td>1.375758</td>\n",
       "      <td>djf</td>\n",
       "      <td>172.45</td>\n",
       "      <td>4.508497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>4.980796</td>\n",
       "      <td>2.745458</td>\n",
       "      <td>0.880343</td>\n",
       "      <td>0.126688</td>\n",
       "      <td>0.783664</td>\n",
       "      <td>Evergreen Needleleaf Forest</td>\n",
       "      <td>0.187307</td>\n",
       "      <td>1.929801</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12020000</th>\n",
       "      <td>7.499240</td>\n",
       "      <td>2.739657</td>\n",
       "      <td>-0.776442</td>\n",
       "      <td>0.043553</td>\n",
       "      <td>0.365325</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.362069</td>\n",
       "      <td>djf</td>\n",
       "      <td>176.45</td>\n",
       "      <td>4.788331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9964</td>\n",
       "      <td>4.401553</td>\n",
       "      <td>2.592355</td>\n",
       "      <td>0.861865</td>\n",
       "      <td>0.139503</td>\n",
       "      <td>0.558829</td>\n",
       "      <td>Evergreen Needleleaf Forest</td>\n",
       "      <td>0.205294</td>\n",
       "      <td>2.064703</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12025000</th>\n",
       "      <td>4.707979</td>\n",
       "      <td>2.094823</td>\n",
       "      <td>-0.780452</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>0.444952</td>\n",
       "      <td>10.50</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>djf</td>\n",
       "      <td>183.00</td>\n",
       "      <td>4.945946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>4.977506</td>\n",
       "      <td>3.118564</td>\n",
       "      <td>0.871182</td>\n",
       "      <td>0.177770</td>\n",
       "      <td>0.680921</td>\n",
       "      <td>Mixed Forests</td>\n",
       "      <td>0.225128</td>\n",
       "      <td>2.188930</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            p_mean  pet_mean  p_seasonality  frac_snow   aridity  \\\n",
       "gauge_id                                                           \n",
       "10396000  1.560339  3.394634      -0.575570   0.465490  2.175574   \n",
       "12010000  7.927943  1.967121      -0.761100   0.023636  0.248125   \n",
       "12013500  6.874938  2.116710      -0.799301   0.017416  0.307888   \n",
       "12020000  7.499240  2.739657      -0.776442   0.043553  0.365325   \n",
       "12025000  4.707979  2.094823      -0.780452   0.029593  0.444952   \n",
       "\n",
       "          high_prec_freq  high_prec_dur high_prec_timing  low_prec_freq  \\\n",
       "gauge_id                                                                  \n",
       "10396000           24.00       1.307902              mam         277.90   \n",
       "12010000            9.35       1.316901              djf         169.90   \n",
       "12013500           11.35       1.375758              djf         172.45   \n",
       "12020000            7.90       1.362069              djf         176.45   \n",
       "12025000           10.50       1.578947              djf         183.00   \n",
       "\n",
       "          low_prec_dur  ... frac_forest   lai_max  lai_diff   gvf_max  \\\n",
       "gauge_id                ...                                             \n",
       "10396000      7.236979  ...      0.0045  0.758705  0.565572  0.331168   \n",
       "12010000      4.323155  ...      0.9981  4.329237  2.369540  0.860577   \n",
       "12013500      4.508497  ...      0.9896  4.980796  2.745458  0.880343   \n",
       "12020000      4.788331  ...      0.9964  4.401553  2.592355  0.861865   \n",
       "12025000      4.945946  ...      0.8617  4.977506  3.118564  0.871182   \n",
       "\n",
       "          gvf_diff  dom_land_cover_frac                   dom_land_cover  \\\n",
       "gauge_id                                                                   \n",
       "10396000  0.177819             0.999126                       Grasslands   \n",
       "12010000  0.133434             0.607243      Evergreen Needleleaf Forest   \n",
       "12013500  0.126688             0.783664      Evergreen Needleleaf Forest   \n",
       "12020000  0.139503             0.558829      Evergreen Needleleaf Forest   \n",
       "12025000  0.177770             0.680921                    Mixed Forests   \n",
       "\n",
       "          root_depth_50  root_depth_99  huc  \n",
       "gauge_id                                     \n",
       "10396000       0.120052       1.500000   17  \n",
       "12010000       0.201421       2.035654   17  \n",
       "12013500       0.187307       1.929801   17  \n",
       "12020000       0.205294       2.064703   17  \n",
       "12025000       0.225128       2.188930   17  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data path\n",
    "data_dir = Path(\"../data/CAMELS_US\")\n",
    "\n",
    "# Load the attributes\n",
    "attributes_df = load_camels_us_attributes(data_dir)\n",
    "\n",
    "# Filter for HUC 17\n",
    "huc_17_df = attributes_df[attributes_df['huc'] == '17']\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "huc_17_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "873f4c6e-3a69-4681-9c3a-646857d441fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "1988-10-01     0.179748\n",
      "1988-10-02     0.156145\n",
      "1988-10-03     0.148883\n",
      "1988-10-04     0.152514\n",
      "1988-10-05     0.176117\n",
      "                ...    \n",
      "2014-12-27     8.224851\n",
      "2014-12-28    10.367307\n",
      "2014-12-29     9.041890\n",
      "2014-12-30     6.844965\n",
      "2014-12-31     5.410609\n",
      "Name: QObs, Length: 9588, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Selected Basin as example\n",
    "basin_id = '14187000' # WILEY CREEK NEAR FOSTER, OR\n",
    "area = 134.75*1e6\n",
    "\n",
    "# Load the discharge data\n",
    "discharge_series = load_camels_us_discharge(data_dir, basin_id, area)\n",
    "print(discharge_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7ad9a1c-f556-418b-9ddd-9de070a263bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(            Year  Mnth  Day  Hr   dayl(s)  prcp(mm/day)  srad(W/m2)  swe(mm)  \\\n",
      "date                                                                           \n",
      "1980-01-01  1980     1    1  12  31449.60         12.21       71.02      0.0   \n",
      "1980-01-02  1980     1    2  12  31449.60          5.02      111.11      0.0   \n",
      "1980-01-03  1980     1    3  12  31449.60         13.07       92.87      0.0   \n",
      "1980-01-04  1980     1    4  12  31480.03         10.84       55.56      0.0   \n",
      "1980-01-05  1980     1    5  12  31795.19         38.25       92.26      0.0   \n",
      "...          ...   ...  ...  ..       ...           ...         ...      ...   \n",
      "2014-12-27  2014    12   27  12  31134.43          0.00      120.79      0.0   \n",
      "2014-12-28  2014    12   28  12  31347.50         20.68       80.97      0.0   \n",
      "2014-12-29  2014    12   29  12  31449.60         16.33      128.15      0.0   \n",
      "2014-12-30  2014    12   30  12  31449.60          3.84      161.51      0.0   \n",
      "2014-12-31  2014    12   31  12  31449.60          0.00      197.89      0.0   \n",
      "\n",
      "            tmax(C)  tmin(C)  vp(Pa)  \n",
      "date                                  \n",
      "1980-01-01     7.22     2.59  738.17  \n",
      "1980-01-02     8.12     0.48  633.21  \n",
      "1980-01-03     6.64     0.46  632.88  \n",
      "1980-01-04     5.49     2.05  710.45  \n",
      "1980-01-05     5.88    -0.15  610.42  \n",
      "...             ...      ...     ...  \n",
      "2014-12-27     4.73    -0.06  607.63  \n",
      "2014-12-28     4.50     0.47  629.08  \n",
      "2014-12-29     2.89    -4.27  454.51  \n",
      "2014-12-30     0.11    -7.69  344.39  \n",
      "2014-12-31     3.68    -6.54  366.88  \n",
      "\n",
      "[12784 rows x 11 columns], 134104036)\n",
      "(            Year  Mnth  Day  Hr   Dayl(s)  PRCP(mm/day)  SRAD(W/m2)  SWE(mm)  \\\n",
      "date                                                                           \n",
      "1980-01-01  1980     1    1  12  31449.60          0.92      127.41      0.0   \n",
      "1980-01-02  1980     1    2  12  31449.60         10.68      134.35      0.0   \n",
      "1980-01-03  1980     1    3  12  31449.60          6.06       91.64      0.0   \n",
      "1980-01-04  1980     1    4  12  31480.05         34.74       81.96      0.0   \n",
      "1980-01-05  1980     1    5  12  31795.20         17.86       90.56      0.0   \n",
      "...          ...   ...  ...  ..       ...           ...         ...      ...   \n",
      "2008-12-27  2008    12   27  12  31347.54         24.34      151.17      0.0   \n",
      "2008-12-28  2008    12   28  12  31449.60         37.59      108.00      0.0   \n",
      "2008-12-29  2008    12   29  12  31449.60         20.31      159.59      0.0   \n",
      "2008-12-30  2008    12   30  12  31449.60          8.33      169.68      0.0   \n",
      "2008-12-31  2008    12   31  12  31449.60         18.00      174.22      0.0   \n",
      "\n",
      "            Tmax(C)  Tmin(C)  Vp(Pa)  \n",
      "date                                  \n",
      "1980-01-01     5.46     5.46  687.97  \n",
      "1980-01-02     4.15     4.15  630.74  \n",
      "1980-01-03     3.71     3.71  636.39  \n",
      "1980-01-04     3.26     3.26  655.10  \n",
      "1980-01-05     3.48     3.48  649.38  \n",
      "...             ...      ...     ...  \n",
      "2008-12-27    -1.89    -1.89  450.16  \n",
      "2008-12-28     3.52     3.52  694.18  \n",
      "2008-12-29     3.58     3.58  656.29  \n",
      "2008-12-30     1.18     1.18  521.14  \n",
      "2008-12-31     0.21     0.21  481.20  \n",
      "\n",
      "[10593 rows x 11 columns], 134104036)\n",
      "(            Year  Mnth  Day  Hr   Dayl(s)  PRCP(mm/day)  SRAD(W/m2)  SWE(mm)  \\\n",
      "date                                                                           \n",
      "1980-01-01  1980     1    1  12  31449.60         12.93      107.26      0.0   \n",
      "1980-01-02  1980     1    2  12  31449.60          4.54      119.55      0.0   \n",
      "1980-01-03  1980     1    3  12  31449.60          7.27      220.16      0.0   \n",
      "1980-01-04  1980     1    4  12  31480.05          3.77      110.43      0.0   \n",
      "1980-01-05  1980     1    5  12  31795.20         46.43      164.55      0.0   \n",
      "...          ...   ...  ...  ..       ...           ...         ...      ...   \n",
      "2014-12-27  2014    12   27  12  31134.45          1.48      114.63      0.0   \n",
      "2014-12-28  2014    12   28  12  31347.54         13.27      115.88      0.0   \n",
      "2014-12-29  2014    12   29  12  31449.60         12.87      159.72      0.0   \n",
      "2014-12-30  2014    12   30  12  31449.60          0.24      251.65      0.0   \n",
      "2014-12-31  2014    12   31  12  31449.60          0.00      240.52      0.0   \n",
      "\n",
      "            Tmax(C)  Tmin(C)  Vp(Pa)  \n",
      "date                                  \n",
      "1980-01-01     5.38     5.38  806.08  \n",
      "1980-01-02     4.82     4.82  769.48  \n",
      "1980-01-03     4.04     4.04  683.01  \n",
      "1980-01-04     5.12     5.12  657.46  \n",
      "1980-01-05     6.10     6.10  877.12  \n",
      "...             ...      ...     ...  \n",
      "2014-12-27     2.62     2.62  611.85  \n",
      "2014-12-28     2.85     2.85  641.82  \n",
      "2014-12-29     2.00     2.00  568.19  \n",
      "2014-12-30    -3.87    -3.87  299.97  \n",
      "2014-12-31    -2.95    -2.95  246.89  \n",
      "\n",
      "[12784 rows x 11 columns], 134104036)\n"
     ]
    }
   ],
   "source": [
    "forcings_data = load_camels_us_forcings(data_dir, basin_id, forcings='daymet')\n",
    "print(forcings_data)\n",
    "forcings_data = load_camels_us_forcings(data_dir, basin_id, forcings='maurer')\n",
    "print(forcings_data)\n",
    "forcings_data = load_camels_us_forcings(data_dir, basin_id, forcings='nldas')\n",
    "print(forcings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4bcce-dfcc-407f-aa89-2bbb39078712",
   "metadata": {},
   "source": [
    "## Base Model - LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fc9528-2bbc-4dce-a3f9-52f51aec305c",
   "metadata": {},
   "source": [
    "Machine learning has been widely used to produce accurate predictions for optimizing water allocation, flood control, and sustainable environmental practices. Machine learning techniques have emerged as powerful tools in the field of hydrological prediction, offering the potential to enhance accuracy and efficiency. Among these techniques, Long Short-Term Memory (LSTM) networks have gained prominence for their ability to model complex temporal dependencies in data. The application of LSTM models in hydrological prediction involves leveraging their capacity to analyze and learn patterns from historical hydrological data. By understanding the intricate relationships between various meteorological and hydrological variables, LSTMs can generate predictions that contribute to more informed decision-making in water resource management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67186b1-67a7-420c-afa6-7fc6bf1eba5f",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "  <img src=\"Images/LSTM.png\" width=600/>\n",
    "<figcaption>LSTM Model\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb149a-065d-488d-8c94-1f9f56457a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brief explanation about the cudaLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235db777-ee44-4527-b346-c29fa450bc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207acb61-d9ac-480e-a809-966ac73f6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include some explanation for the hidden size we have chosen -> looking at training, val, test loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0f8b6-d053-4010-afd9-38e38cdf8d14",
   "metadata": {},
   "source": [
    "## Model Head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b659021-a640-418c-b8ef-d9325e8a2df9",
   "metadata": {},
   "source": [
    "The model head in this case means the final part of the neural network architecture responsible for generating the specific output format required for a task, which in this case can result in probabilistic modeling. In this project we look at the Monte Carlo Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841fabc0-5752-4671-af73-342e7e46774c",
   "metadata": {},
   "source": [
    "### Monte Carlo Dropout (MCD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2845b5-196b-4d87-9ed1-04a5a8a3bf96",
   "metadata": {},
   "source": [
    "Monte Carlo Dropout (MCD) provides a way to estimate the uncertainty of our predictions. In this case dropout is used with a certain dropout rate to randomly inactive certain neural network nodes. This results in a different network structure each time the model is evaluated during training. By repeating this process multiple times an ensemble of many sub-networks is created which all produce predictions. From this ensemble of predictions an uncertainty interval can be created and later on evaluated. \n",
    "\n",
    "<center><figure>\n",
    "  <img src=\"Images/MCD.png\" width=600/>\n",
    "<figcaption>Monte Carlo Dropout\n",
    "</figure></center>\n",
    "\n",
    "The first step was to find a suitable dropout rate to use during the Monte Carlo Dropout process. By using different dropout rates between the range of 0.2-0.5, we tested which dropout rate would be best for our project to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f4490-92ff-498c-9ac3-f8c43650dcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba07d0d6-40d8-4738-a504-322d0936f8f9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dce577-9921-4459-bb64-1c1056244f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training part, hyperparameters chosen, any configuration in each model present here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80441020-aebc-443f-9376-59f0ba8b14f6",
   "metadata": {},
   "source": [
    "|               | GMM                      | CMAL                     | UMAL                     | MCD                      |\r\n",
    "|---------------|--------------------------|--------------------------|--------------------------|--------------------------|\r\n",
    "| Training period       | 1 Jan 1980–31 Dec 1999   | 1 Jan 1980–31 Dec 1999   | 1 Jan 1980–31 Dec 1999   | 1 Jan 1980–31 Dec 1999   |\r\n",
    "| Validation period     | 1 Jan 2000–31 Dec 2004   | 1 Jan 2000–31 Dec 2004   | 1 Jan 2000–31 Dec 2004   | 1 Jan 2000–31 Dec 2004   |\r\n",
    "| Test period           | 1 Jan 2005–31 Dec 2009   | 1 Jan 2005–31 Dec 2009   | 1 Jan 2005–31 Dec 2009   | 1 Jan 2005–31 Dec 2009   |\r\n",
    "| Training loss         | Negative log-likelihood  | Negative log-likelihood  | Negative log-likelihood  | MSE                      |\r\n",
    "| CAMELS attributes     | Yes                      | Yes                      | Yes                      | Yes                      |\r\n",
    "| Input products        | DayMet, Maurer, NLDAS    | DayMet, Maurer, NLDAS    | DayMet, Maurer, NLDAS    | DayMet, Maurer, NLDAS    |\r\n",
    "| Regularization: noise | Yes                      | Yes                      | Yes                      | Yes                      |\r\n",
    "| Regularization: dropout | Yes                      | Yes                      | Yes                      | Yes                      |\r\n",
    "| Sampling space for τ  | NA                       | NA                       | NA                       | (0.01, 0.99)             |\r\n",
    "| Gradient clipping     | Yes                      | Yes                      | No                       | Yes            | Hidden size LSTM     | 20    | 20    | 20    | 20    |\r\n",
    "| Number of components | 10     | 3      | NA     | NA     |\r\n",
    "| Regularization: noise| 0.2    | 0.2    | 0.2    | 0.1    |\r\n",
    "| Regularization: dropout| 0.4  |40.5    |40.5    |2.75   |\r\n",
    "| Batch size           | 256    | 256    | 256    | 256    |\r\n",
    "| Learning rate        | 0.001  | 0.0005 | 0.0005 | 0.001  |           |\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024018fe-b7a8-4ae6-aebf-e326731ec1f2",
   "metadata": {},
   "source": [
    "## Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617057e8-7edb-43ef-a149-85bd5af29dd9",
   "metadata": {},
   "source": [
    "In the code above the LSTM model was trained. Now that that is achieved we can test the model performance and show the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0031f-80bf-40dc-87da-f72b5f5d625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows model results in the same basin "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe4ed8d-9baa-4627-89ae-91d5876a5074",
   "metadata": {},
   "source": [
    "## Evaluation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2edb67-a683-424c-8fbf-5a2a77935e5c",
   "metadata": {},
   "source": [
    "The final step is to evaluate the model and the results obtained from the model and Monte Carlo Dropout. We do this in two ways: \n",
    "\n",
    "- #### Deterministic:\n",
    "\n",
    "The Monte Carlo Dropout, shown previously, results in a thousand different prediction time-series for the discharge. It is an option to compare these deterministically to the observations and the used LSTM model without Monte Carlo Dropout. Ensembling is a way to get a deterministic result from multiple predicitons, in our case we have taken the median of all predictions and combined these into one time-series. In the end, this ensemble can be shown combined with the observations and its performance can be compared to the deterministic result we got from just using the LSTM model.\n",
    "\n",
    "- #### Probabilistic:\n",
    "\n",
    "One of the main objectives of our project was to see whether probabilistic predictions would be useful in making discharge predictions. As in most cases model used for discharge predictions only return deterministic results, but they do not give us an indication about the uncertainty in these predictions. Using Monte Carlo Dropout probabilistic predictions can be made. The thousand prediction time-series can be used to make a prediction interval, for which we used a 95% as the set interval. \n",
    "\n",
    "To evaluate these intervals we introduced two evaluation metrics, the Prediction Interval Coverage Probability (PICP) and the Prediction Interval Normalized Average Width (PINAW). The PICP is a metric that measures the percentage of target observations which are enclosed in the prediction interval. \n",
    "\n",
    "$$PICP = \\frac{1}{n}  * \\sum \\limits _{i=1} ^{n} c_{i}$$\n",
    "\n",
    "\n",
    "The PINAW is defined as the ratio between the average width of the prediction interval and the range of the observations.\n",
    "\n",
    "$$PINAW = \\frac{1}{nR} * \\sum \\limits _{i=1} ^{n} (u_{i} - l_{i})$$\n",
    "\n",
    "Comparing these two probabilistic evaluation metric we try to find the optimal dropout rate for Monte Carlo Dropout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c561c0-f948-4bac-96e3-5c89f4481a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation part, hyperparameters chosen, any configuration in each model present here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2840bc8e-51a9-4972-94e3-c28306c98120",
   "metadata": {},
   "source": [
    "### Deterministic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cdc57-d416-4d3a-912e-8d2665926977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "802abb39-406a-4cfb-ab65-5eddafa4e9bc",
   "metadata": {},
   "source": [
    "### Probabilistic Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee4ac6-db5b-4efa-a0b4-e711ceb00367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c0c9252-49c9-4814-ba0c-32a10c8e81a2",
   "metadata": {},
   "source": [
    "## Transferability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb7982a8-2d32-4929-92ca-3389083342c4",
   "metadata": {},
   "source": [
    "As an extra objective, we tried to use Transfer Learning as well. Here, we used our pretrained model which we obtained previously to test it on another HUC dataset. This HUC has different characteristics than the HUC used during training. \n",
    "\n",
    "By using Transfer Learning we try to find out whether it is possible to use our pretrained model for other basins as well. In the code below, we test and show the results of the Transfer Learning. This examination has the aim to determine how feasible the pretrained model is for diverse basins and thereby giving insight into the capacity of the model to generalize across different environmental characteristics.\n",
    "\n",
    "\n",
    "<center><figure>\n",
    "  <img src=\"Images/Transfer_Learning.png\" width=600/>\n",
    "<figcaption>Transfer Learning\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8807b60-e9a9-4363-a67c-9a5dbfd280c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the results of probabilistic evaluation for different basin in different HUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68860090-80a4-4927-a9b6-a3a2a4e3f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779bc0b9-b4c1-4f54-a717-f5733554e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344300a7-8d78-4188-a90a-b34d3b7067f6",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c162f7e2-cdc2-489e-8913-c4c3816e11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain what we have seen and what we can conclude from that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d086c-294d-4fcf-b4ba-c386a05ab85b",
   "metadata": {},
   "source": [
    "# Reflection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f215387-cbc2-4616-a08d-dfdd2f1ba1cb",
   "metadata": {},
   "source": [
    "During the period of our project, the group walked into a few issues that caused our objectives to change. Originally, the plan was to use four uncertainty methods with which we would make probabilistic predictions for discharge estimations. These methods were the Monte Carlo Dropout, Gaussian Mixtures Model, Countable Mixture of Asymmetric Laplacians and Uncountable Mixture of Asymmetric Laplacians. \n",
    "\n",
    "Our approach was aimed to investigate these methodologies for uncertainty estimation. However, as we were working on the project, it became clear that our initial excitement led to us underestimating the amount of work that was required. The original workplan (see Figure below) showed our initial plan to apply these four uncertainty methods for both deterministic and probabilistic predictions. The goal was to compare these method to each other and see whether a certain method was most effective.\n",
    "\n",
    "<center><figure>\n",
    "  <img src=\"Images/CEGM2003.png\" width=600/>\n",
    "<figcaption>Previous workplan\n",
    "</figure></center>\n",
    "\n",
    "Regrettably, due to the underestimated work, it was necessary to change our objective. For that reason we decided to focus solely on the Monte Carlo Dropout method. Even though we had to change our original plan, this change ensured that we had enough time to finish the project and that the project was meaningful research into the use of probabilistic predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb510e9a-125d-4c19-87e1-a7160e9e7c5e",
   "metadata": {},
   "source": [
    "# Project Logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fe209c-3f82-46e0-938d-28917a275dba",
   "metadata": {},
   "source": [
    "This is the logbook we used during the project. Showing the main tasks we performed during the project and who was responsible for what. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32466116-b532-4c57-9e2e-e1c646f6b131",
   "metadata": {},
   "source": [
    "<center><figure>\n",
    "  <img src=\"Images/Logbook.png\" width=600/>\n",
    "<figcaption>Project Logbook\n",
    "</figure></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52453b6-b9a0-467a-a6b3-c139d0133d48",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813e5ad1-256e-4449-938c-560f7e0748e0",
   "metadata": {},
   "source": [
    "Klotz, D., Kratzert, F., Gauch, M., Sampson, A. K., Brandstetter, J., Klambauer, G., Hochreiter, S., & Nearing, G. (2022). Uncertainty estimation with deep learning for rainfall–runoff modeling. Hydrology and Earth System Sciences, 26(6), 1673–1693. https://doi.org/10.5194/hess-26-1673-2022\n",
    "\n",
    "Kratzert, F., Klotz, D., Brenner, C., Schulz, K., & Herrnegger, M. (2018). Rainfall–runoff modelling using Long Short-Term Memory (LSTM) networks. Hydrology and Earth System Sciences, 22(11), 6005–6022. https://doi.org/10.5194/hess-22-6005-2018\n",
    "\n",
    "Taormina, R., & Chau, K. W. (2015). ANN-based interval forecasting of streamflow discharges using the LUBE method and MOFIPS. Engineering Applications of Artificial Intelligence, 45, 429–440. https://doi.org/10.1016/j.engappai.2015.07.019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d2ed-7caf-4195-b20c-adf36af8756d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
